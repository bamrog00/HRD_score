{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd99d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d067b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaplesheet has already been created and therefore the clinical data as well\n"
     ]
    }
   ],
   "source": [
    "# First the sample_sheets and clinical data from the two batches need to be merged.\n",
    "# This will likely already be done\n",
    "\n",
    "path = '../data/metadata/'\n",
    "file = 'gdc_samplesheet.csv'\n",
    "\n",
    "if os.path.exists(path+file):\n",
    "    print('Smaplesheet has already been created and therefore the clinical data as well')\n",
    "    \n",
    "else:\n",
    "    batch_1_sheet = pd.read_csv('../data/metadata/batch1/gdc_sample_sheet.2023-02-21.tsv', sep='\\t', header = 0)\n",
    "    batch_2_sheet = pd.read_csv('../data/metadata/batch2/gdc_sample_sheet.2023-02-21.tsv', sep='\\t', header = 0)\n",
    "    batch_1_clinical = pd.read_csv('../data/metadata/batch1/clinical.tsv', sep='\\t', header = 0)\n",
    "    batch_2_clinical = pd.read_csv('../data/metadata/batch2/clinical.tsv', sep='\\t', header = 0)\n",
    "    \n",
    "    sample_sheet = pd.concat([batch_1_sheet,batch_2_sheet])\n",
    "    clinical = pd.concat([batch_1_clinical,batch_2_clinical])\n",
    "    \n",
    "    sample_sheet.to_csv(path+file, header = True, sep = ',', index = None)\n",
    "    clinical.to_csv(path+'clinical.csv', header = True, sep = ',', index = None)\n",
    "    \n",
    "    #Check if everthing is there (from missing_files we know there should be 11582 files in case for the sample sheet)\n",
    "    print(len(batch_1_sheet)+len(batch_2_sheet))\n",
    "    print(len(sample_sheet))\n",
    "    print(len(batch_1_clinical)+len(batch_2_clinical))\n",
    "    print(len(clinical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update code table from TCGA, adding TARGET codes and Project ID\n",
    "# This also might already be done\n",
    "code_table = pd.read_csv('../data/TCGA_code_tables/diseaseStudy.tsv', sep='\\t', header = 0)\n",
    "code_table['Project ID'] = 'TCGA-'+ code_table['Study Abbreviation']\n",
    "\n",
    "\n",
    "target_rows = pd.DataFrame({'Study Abbreviation': ['ALL-P2','AML','CCSK','OS'],\n",
    "                            'Study Name': ['Acute Lymphoblastic Leukemia - Phase II','Acute Myeloid Leukemia','Clear Cell Sarcoma of the Kidney','Osteosarcoma'],\n",
    "                            'Project ID': ['TARGET-ALL-P2','TARGET-AML','TARGET-CCSK','TARGET-OS']})\n",
    "code_table = pd.concat([code_table, target_rows]).reset_index(drop=True)\n",
    "code_table.to_csv('../data/TCGA_code_tables/diseaseStudy_updated.csv', sep=',', header = True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0d5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries used for mapping sample types\n",
    "# We broke down the sample types to: Primary, Recurrent, Metastatic\n",
    "sampletype_mapping = {\n",
    "    'Additional - New Primary, Blood Derived Normal': 'Additional - New Primary, Blood Derived Normal',\n",
    "    'Blood Derived Normal, Additional - New Primary': 'Additional - New Primary, Blood Derived Normal',\n",
    "    'Blood Derived Normal, Metastatic': 'Metastatic, Blood Derived Normal',\n",
    "    'Blood Derived Normal, Primary Blood Derived Cancer - Bone Marrow': 'Primary Blood Derived Cancer - Bone Marrow, Blood Derived Normal',\n",
    "    'Blood Derived Normal, Primary Blood Derived Cancer - Peripheral Blood': 'Primary Blood Derived Cancer - Peripheral Blood, Blood Derived Normal',\n",
    "    'Blood Derived Normal, Primary Tumor': 'Primary Tumor, Blood Derived Normal',\n",
    "    'Blood Derived Normal, Recurrent Blood Derived Cancer - Bone Marrow': 'Recurrent Blood Derived Cancer - Bone Marrow, Blood Derived Normal',\n",
    "    'Blood Derived Normal, Recurrent Tumor': 'Recurrent Tumor, Blood Derived Normal',\n",
    "    'Bone Marrow Normal, Primary Blood Derived Cancer - Bone Marrow': 'Primary Blood Derived Cancer - Bone Marrow, Bone Marrow Normal',\n",
    "    'Bone Marrow Normal, Primary Blood Derived Cancer - Peripheral Blood': 'Primary Blood Derived Cancer - Peripheral Blood, Bone Marrow Normal',\n",
    "    'Bone Marrow Normal, Primary Tumor': 'Primary Tumor, Bone Marrow Normal',\n",
    "    'Bone Marrow Normal, Recurrent Blood Derived Cancer - Bone Marrow': 'Recurrent Blood Derived Cancer - Bone Marrow, Bone Marrow Normal',\n",
    "    'Buccal Cell Normal, Primary Tumor':'Primary Tumor, Buccal Cell Normal',\n",
    "    'Metastatic, Blood Derived Normal': 'Metastatic, Blood Derived Normal',\n",
    "    'Metastatic, Solid Tissue Normal': 'Metastatic, Solid Tissue Normal',\n",
    "    'Primary Blood Derived Cancer - Bone Marrow, Blood Derived Normal': 'Primary Blood Derived Cancer - Bone Marrow, Blood Derived Normal',\n",
    "    'Primary Blood Derived Cancer - Bone Marrow, Bone Marrow Normal': 'Primary Blood Derived Cancer - Bone Marrow, Bone Marrow Normal',\n",
    "    'Primary Blood Derived Cancer - Peripheral Blood, Blood Derived Normal': 'Primary Blood Derived Cancer - Peripheral Blood, Blood Derived Normal',\n",
    "    'Primary Blood Derived Cancer - Peripheral Blood, Bone Marrow Normal': 'Primary Blood Derived Cancer - Peripheral Blood, Bone Marrow Normal',\n",
    "    'Primary Blood Derived Cancer - Peripheral Blood, Solid Tissue Normal' : 'Primary Blood Derived Cancer - Peripheral Blood, Solid Tissue Normal',\n",
    "    'Primary Tumor, Blood Derived Normal' : 'Primary Tumor, Blood Derived Normal',\n",
    "    'Primary Tumor, Bone Marrow Normal': 'Primary Tumor, Bone Marrow Normal',\n",
    "    'Primary Tumor, Buccal Cell Normal': 'Primary Tumor, Buccal Cell Normal',\n",
    "    'Primary Tumor, Solid Tissue Normal': 'Primary Tumor, Solid Tissue Normal',\n",
    "    'Recurrent Blood Derived Cancer - Bone Marrow, Bone Marrow Normal': 'Recurrent Blood Derived Cancer - Bone Marrow, Bone Marrow Normal',\n",
    "    'Recurrent Tumor, Blood Derived Normal': 'Recurrent Tumor, Blood Derived Normal',\n",
    "    'Recurrent Tumor, Solid Tissue Normal':'Recurrent Tumor, Solid Tissue Normal',\n",
    "    'Solid Tissue Normal, Metastatic': 'Metastatic, Solid Tissue Normal',\n",
    "    'Solid Tissue Normal, Primary Blood Derived Cancer - Peripheral Blood': 'Primary Blood Derived Cancer - Peripheral Blood, Solid Tissue Normal',\n",
    "    'Solid Tissue Normal, Primary Tumor': 'Primary Tumor, Solid Tissue Normal',\n",
    "    'Solid Tissue Normal, Recurrent Tumor': 'Recurrent Tumor, Solid Tissue Normal' \n",
    "}\n",
    "\n",
    "type_mapping = {\n",
    "    'Additional - New Primary, Blood Derived Normal' : 'Primary',\n",
    "    'Metastatic, Blood Derived Normal': 'Metastatic',\n",
    "    'Metastatic, Solid Tissue Normal' : 'Metastatic',\n",
    "    'Primary Blood Derived Cancer - Bone Marrow, Blood Derived Normal': 'Primary',\n",
    "    'Primary Blood Derived Cancer - Bone Marrow, Bone Marrow Normal' : 'Primary',\n",
    "    'Primary Blood Derived Cancer - Peripheral Blood, Blood Derived Normal' : 'Primary',\n",
    "    'Primary Blood Derived Cancer - Peripheral Blood, Bone Marrow Normal' : 'Primary',\n",
    "    'Primary Blood Derived Cancer - Peripheral Blood, Solid Tissue Normal' : 'Primary',\n",
    "    'Primary Tumor, Blood Derived Normal' : 'Primary',\n",
    "    'Primary Tumor, Bone Marrow Normal': 'Primary',\n",
    "    'Primary Tumor, Buccal Cell Normal': 'Primary',\n",
    "    'Primary Tumor, Solid Tissue Normal': 'Primary',\n",
    "    'Recurrent Blood Derived Cancer - Bone Marrow, Bone Marrow Normal': 'Recurrent',\n",
    "    'Recurrent Tumor, Blood Derived Normal': 'Recurrent',\n",
    "    'Recurrent Tumor, Solid Tissue Normal':'Recurrent',\n",
    "    'Recurrent Blood Derived Cancer - Bone Marrow, Blood Derived Normal': 'Recurrent'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba83903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84424/3141092716.py:2: DtypeWarning: Columns (3,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clinical =  pd.read_csv('../data/metadata/clinical.csv', sep=',', header = 0)\n"
     ]
    }
   ],
   "source": [
    "# Loading results and metadata\n",
    "sample_sheet = pd.read_csv('../data/metadata/gdc_samplesheet.csv', sep=',', header = 0)\n",
    "clinical =  pd.read_csv('../data/metadata/clinical.csv', sep=',', header = 0)\n",
    "HRD_scores = pd.read_csv('../data/HRD_scores_pan_cancer.csv', sep=',', header = 0)\n",
    "\n",
    "# Add column, case_id from the file names\n",
    "file_names = HRD_scores['File Name']\n",
    "case_ids = [s.split('.')[1] for s in file_names]\n",
    "HRD_scores.insert(1, \"case_id\", case_ids)\n",
    "\n",
    "# Split up Case ID from Sample Sheet and add it as case_submitter_id\n",
    "case_ids_double = sample_sheet['Case ID']\n",
    "case_ids = [s.split(',')[0] for s in case_ids_double]\n",
    "sample_sheet = sample_sheet.assign(case_submitter_id=case_ids)\n",
    "\n",
    "# Merge HRD scores with sample file\n",
    "score_sample = pd.merge(HRD_scores, sample_sheet, on = 'File Name')\n",
    "\n",
    "# Preparing clincial data (drop dublicates, dublicates are due to different treatment of a patient)\n",
    "clinical.rename(columns={'project_id':'Project ID'}, inplace=True)\n",
    "pid_primarydiag = clinical[['case_submitter_id','Project ID','primary_diagnosis']]\n",
    "\n",
    "pid_primarydiag_unique = pid_primarydiag.drop_duplicates(\n",
    "  subset = ['case_submitter_id','Project ID','primary_diagnosis'],\n",
    "  keep = 'last').reset_index(drop = True)\n",
    "\n",
    "\n",
    "# Merge with clinical (some of the cases (26) do not have clinical data, but it is still merged)\n",
    "scsa_clinical = pd.merge(score_sample, pid_primarydiag_unique, how = 'left', on = ['case_submitter_id','Project ID'])\n",
    "\n",
    "\n",
    "# Adding new columns for the types (ProjectID_Type (combination of ID and type, Type (Primary, Recurrent, Metastatic))\n",
    "scsa_clinical['sampleType_correct'] = \"\"\n",
    "\n",
    "for sampletype in sampletype_mapping:\n",
    "    scsa_clinical.loc[scsa_clinical['Sample Type'] == sampletype,'sampleType_correct'] = sampletype_mapping[sampletype]\n",
    "\n",
    "scsa_clinical['Type'] = \"\"\n",
    "\n",
    "for type_ in type_mapping:\n",
    "    scsa_clinical.loc[scsa_clinical['sampleType_correct'] == type_,'Type'] = type_mapping[type_]\n",
    "\n",
    "scsa_clinical['PID_Type'] = scsa_clinical['Project ID'] + ' ' + scsa_clinical['Type']\n",
    "\n",
    "# Add the full names of the cancers (aka Study Name)\n",
    "code_table = pd.read_csv('../data/TCGA_code_tables/diseaseStudy_updated.csv', sep=',', header = 0)\n",
    "code_table = code_table[['Study Name','Project ID']]\n",
    "\n",
    "scsa_clinical = pd.merge(scsa_clinical, code_table, on = ['Project ID'])\n",
    "\n",
    "\n",
    "\n",
    "# Save all and only primary results\n",
    "scsa_clinical.to_csv('../data/HRD_scores_pan_cancer_annotated_typecorrect.csv', sep=',', header = True, index = None)\n",
    "\n",
    "scsa_clinical_primary = scsa_clinical.loc[scsa_clinical['Type'] == 'Primary']\n",
    "scsa_clinical_primary.to_csv('../data/HRD_scores_pan_cancer_annotated_primary.csv', sep=',', header = True, index = None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81741e2",
   "metadata": {},
   "source": [
    "# Version 2.0 \n",
    "Splitting up reference (normal) and tumor IDs which makes it easier for matching in the RNA cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0febda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13684/3001679278.py:3: DtypeWarning: Columns (3,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clinical =  pd.read_csv('../data/metadata/clinical.csv', sep=',', header = 0)\n"
     ]
    }
   ],
   "source": [
    "# Loading results and metadata\n",
    "sample_sheet = pd.read_csv('../data/metadata/gdc_samplesheet.csv', sep=',', header = 0)\n",
    "clinical =  pd.read_csv('../data/metadata/clinical.csv', sep=',', header = 0)\n",
    "HRD_scores = pd.read_csv('../data/HRD_scores_pan_cancer.csv', sep=',', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f774d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_save_duplicates(data):\n",
    "    dublicates_rows = data[data.duplicated(subset=['Sample ID'], keep=False)]\n",
    "    \n",
    "    filtered_df = data.drop_duplicates(subset=['Sample ID'], keep=False)\n",
    "    \n",
    "    dublicates_rows.to_csv('../data/samplesheet_removed_dublicates.csv', sep=',', header = True, index = None)\n",
    "    \n",
    "    #print(dublicates_rows.shape)\n",
    "    #print(deduplicated_df.shape)\n",
    "    #print(data.shape)\n",
    "    #print(dublicates_rows.shape[0] + deduplicated_df.shape[0])\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def split_sampleid_types(data):\n",
    "    new_columns = list(data.columns) + ['Sample ID Original', 'Sample Type Original']\n",
    "    new_df = pd.DataFrame(columns=new_columns)\n",
    "\n",
    "    # Iterate over each row in the original dataframe\n",
    "    for _, row in data.iterrows():\n",
    "        # Split the 'Sample ID' and 'Sample Type' values\n",
    "        ids = row['Sample ID'].split(', ')\n",
    "        types = row['Sample Type'].split(', ')\n",
    "\n",
    "        # Create a new dataframe for the split values\n",
    "        split_df = pd.DataFrame()\n",
    "        # Update the 'Sample ID' and 'Sample Type' values in the new dataframe\n",
    "        split_df['Sample ID'] = ids\n",
    "        split_df['Sample Type'] = types\n",
    "        # Store the original unsplit values in the new columns\n",
    "        split_df['Sample ID Original'] = row['Sample ID']\n",
    "        split_df['Sample Type Original'] = row['Sample Type']\n",
    "\n",
    "        # Copy other columns from the original row to the split dataframe\n",
    "        for column in data.columns:\n",
    "            if column not in ['Sample ID', 'Sample Type']:\n",
    "                split_df[column] = row[column]\n",
    "\n",
    "        # Concatenate the split dataframe with the new dataframe\n",
    "        new_df = pd.concat([new_df, split_df], ignore_index=True)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def add_general_sampletype(data):\n",
    "    data['Type'] = ''\n",
    "    s_types = np.unique(list(data['Sample Type']))\n",
    "    for s_type in s_types:\n",
    "        split_string = s_type.split(' ')\n",
    "\n",
    "        if 'Primary' in split_string:\n",
    "            data.loc[data['Sample Type'] == s_type, 'Type'] = 'Primary'\n",
    "        elif 'Metastatic' in split_string:\n",
    "            data.loc[data['Sample Type'] == s_type, 'Type'] = 'Metastatic'\n",
    "        elif 'Recurrent' in split_string:\n",
    "            data.loc[data['Sample Type'] == s_type, 'Type'] = 'Recurrent'\n",
    "        else:\n",
    "            data.loc[data['Sample Type'] == s_type, 'Type'] = 'Normal'\n",
    "    return data\n",
    "\n",
    "def erase_normal_scores(data):\n",
    "    data.loc[data['Type'] == 'Normal', 'HRD_sum'] = np.nan\n",
    "    data.loc[data['Type'] == 'Normal', 'TAI'] = np.nan\n",
    "    data.loc[data['Type'] == 'Normal', 'LST'] = np.nan\n",
    "    data.loc[data['Type'] == 'Normal', 'LOH'] = np.nan\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa968dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sheet = remove_save_duplicates(sample_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bc7a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge HRDresults and sample sheet\n",
    "score_sample = pd.merge(HRD_scores, sample_sheet, on = 'File Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "baf9a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11582, 5)\n",
      "(11194, 8)\n",
      "(11194, 12)\n",
      "22388\n"
     ]
    }
   ],
   "source": [
    "print(HRD_scores.shape)\n",
    "print(sample_sheet.shape)\n",
    "print(score_sample.shape)\n",
    "print(score_sample.shape[0] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "901750c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sample = split_sampleid_types(score_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e87e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sample = add_general_sampletype(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3e5e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sample = erase_normal_scores(score_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c60e23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sample.to_csv('../data/HRD_scores_pan_cancer_annotated_v2.csv', sep=',', header = True, index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d7194",
   "metadata": {},
   "source": [
    "## Tests\n",
    "Test if the data is complete ect.\n",
    "\n",
    "Does not has to be used, was to check during coding\n",
    "\n",
    "Might get deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84810244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks \n",
    "\n",
    "\n",
    "# print(pid_primarydiag[['case_submitter_id','Project ID']].value_counts(ascending = True))\n",
    "# print(pid_primarydiag_unique[['case_submitter_id','Project ID','primary_diagnosis']].value_counts(ascending = True))\n",
    "\n",
    "# print(sample_sheet['case_submitter_id'].isin(clinical['case_submitter_id']).value_counts())\n",
    "# print(HRD_scores['case_id'].isin(clinical['case_id']).value_counts())\n",
    "# print(HRD_scores['case_id'])\n",
    "# print(HRD_scores[HRD_scores['case_id'].duplicated() == True])\n",
    "# print(clinical[clinical['case_id'].duplicated() == True])\n",
    "\n",
    "\n",
    "# df_missing = HRD_scores[~HRD_scores['File Name'].isin(scsa_clinical['File Name'])]\n",
    "# print(len(df_missing))\n",
    "# df_missing = score_sample[~score_sample['File Name'].isin(scsa_clinical['File Name'])]\n",
    "# print(len(HRD_scores))\n",
    "# print(len(sample_sheet))\n",
    "# print(len(clinical))\n",
    "# print(len(df_missing))\n",
    "# print(df_missing['File Name'])\n",
    "# df_missing.to_csv('../data/missing_subtype_files.csv', sep=',', header = True, index = None)\n",
    "\n",
    "# print(sample_sheet['case_submitter_id'].isin(clinical['case_submitter_id']).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad002ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../data/allele_specific_cnv/allele_cnv_txt/*.seg.txt')\n",
    "files = [os.path.basename(file) for file in files]\n",
    "projects = [s.split('.')[0] for s in files]\n",
    "print(len(projects))\n",
    "sum_ = 0\n",
    "for project in np.unique(projects):\n",
    "    print(project + ': ' + str(projects.count(project)))\n",
    "    sum_ = sum_ +  projects.count(project)\n",
    "print(sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6552268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional - New Primary, Blood Derived Normal: 5\n",
      "Blood Derived Normal, Additional - New Primary: 5\n",
      "Blood Derived Normal, Metastatic: 191\n",
      "Blood Derived Normal, Primary Blood Derived Cancer - Bone Marrow: 114\n",
      "Blood Derived Normal, Primary Blood Derived Cancer - Peripheral Blood: 9\n",
      "Blood Derived Normal, Primary Tumor: 4445\n",
      "Blood Derived Normal, Recurrent Blood Derived Cancer - Bone Marrow: 3\n",
      "Blood Derived Normal, Recurrent Tumor: 32\n",
      "Bone Marrow Normal, Primary Blood Derived Cancer - Bone Marrow: 59\n",
      "Bone Marrow Normal, Primary Blood Derived Cancer - Peripheral Blood: 5\n",
      "Bone Marrow Normal, Primary Tumor: 3\n",
      "Bone Marrow Normal, Recurrent Blood Derived Cancer - Bone Marrow: 7\n",
      "Buccal Cell Normal, Primary Tumor: 1\n",
      "Metastatic, Blood Derived Normal: 195\n",
      "Metastatic, Solid Tissue Normal: 2\n",
      "Primary Blood Derived Cancer - Bone Marrow, Blood Derived Normal: 101\n",
      "Primary Blood Derived Cancer - Bone Marrow, Bone Marrow Normal: 54\n",
      "Primary Blood Derived Cancer - Peripheral Blood, Blood Derived Normal: 11\n",
      "Primary Blood Derived Cancer - Peripheral Blood, Bone Marrow Normal: 8\n",
      "Primary Blood Derived Cancer - Peripheral Blood, Solid Tissue Normal: 87\n",
      "Primary Tumor, Blood Derived Normal: 4534\n",
      "Primary Tumor, Bone Marrow Normal: 1\n",
      "Primary Tumor, Buccal Cell Normal: 3\n",
      "Primary Tumor, Solid Tissue Normal: 771\n",
      "Recurrent Blood Derived Cancer - Bone Marrow, Bone Marrow Normal: 15\n",
      "Recurrent Tumor, Blood Derived Normal: 28\n",
      "Recurrent Tumor, Solid Tissue Normal: 6\n",
      "Solid Tissue Normal, Metastatic: 3\n",
      "Solid Tissue Normal, Primary Blood Derived Cancer - Peripheral Blood: 103\n",
      "Solid Tissue Normal, Primary Tumor: 780\n",
      "Solid Tissue Normal, Recurrent Tumor: 1\n",
      "Metastatic types: 2\n"
     ]
    }
   ],
   "source": [
    "sample_type = list(sample_sheet['Sample Type'])\n",
    "sum_ = 0\n",
    "sample_list = list()\n",
    "for type_ in np.unique(sample_type):\n",
    "    words = type_.split(',')\n",
    "    sample_list.append(type_)\n",
    "    if 'Metastatic' in words:\n",
    "        sum_ = sum_ + 1\n",
    "    print(type_ + ': ' + str(sample_type.count(type_)))\n",
    "print('Metastatic types: '+str(sum_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9908db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n"
     ]
    }
   ],
   "source": [
    "gdc_cases = [1067,561,536,517,517,510,509,507,498,493,486,466,454,436,391,369,299,293,284,248,190,183,181,167,162,150,123,90,86,81,80,73,66,53,48,36,11]\n",
    "files_numbers = [1084,589,545,521,574,542,527,544,505,514,491,468,509,436,396,373,301,294,298,254,190,184,182,172,167,156,123,90,86,81,80,92,66,53,48,36,11]\n",
    "diff = list()\n",
    "for i,num in enumerate(gdc_cases):\n",
    "    diff.append(abs(num-files_numbers[i]))\n",
    "print(sum(diff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
